\subsection{Multi-variate normal distribution}

In this exercise we use the notation 
\[
N(m,C)
\]
to denote the multivariate normal distribution with mean $m\in\mathbb{R}^n$ and covariance matrix $C\in\mathbb{R}^{n\times n}$. In particular, $N(0,I)$ denotes the standard normal distribution in $\mathbb{R}^n$.

\subsubsection*{1.}
Let $a\in\mathbb{R}^n$ be a nonzero vector and consider the matrix
\[
C = aa^T.
\]

\subsubsection*{(a) Rank of $C=aa^T$}
For any $x\in\mathbb{R}^n$ we have
\[
C x = aa^T x = a \, (a^T x).
\]
Since $a^T x$ is a scalar, it follows that $Cx$ is always a scalar multiple of $a$. In other words, the image (or column space) of $C$ is contained in $\operatorname{span}\{a\}$. Since $a\neq 0$, this is a one-dimensional subspace. Hence, 
\[
\operatorname{rank}(C)=1.
\]

\subsubsection*{(b) Eigenvector and Eigenvalue of $C=aa^T$}
We next show that $a$ is an eigenvector of $C$. Indeed,
\[
C\,a = aa^T a = a\,(a^T a) = \|a\|^2\,a.
\]
Thus, $a$ is an eigenvector corresponding to the eigenvalue 
\[
\lambda = \|a\|^2.
\]

\subsubsection*{(c) Maximum Likelihood for a One-Dimensional Normal Distribution}
Consider the family of one-dimensional normal distributions with zero mean and variance $\sigma^2$, that is, 
\[
N(0,\sigma^2).
\]
The probability density function (pdf) is given by
\[
p(a\mid \sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{a^2}{2\sigma^2}\right).
\]
For a single observation $a\in\mathbb{R}$, the likelihood function is
\[
L(\sigma^2)=p(a\mid \sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{a^2}{2\sigma^2}\right).
\]
It is more convenient to maximize the logarithm of the likelihood:
\[
\ell(\sigma^2)=\log L(\sigma^2)=-\frac{1}{2}\log(2\pi\sigma^2)-\frac{a^2}{2\sigma^2}.
\]
Differentiate $\ell(\sigma^2)$ with respect to $\sigma^2$:
\[
\frac{d\ell}{d\sigma^2}=-\frac{1}{2\sigma^2}+\frac{a^2}{2(\sigma^2)^2}.
\]
Setting the derivative equal to zero, we obtain
\[
-\frac{1}{2\sigma^2}+\frac{a^2}{2(\sigma^2)^2}=0 
\quad\Longrightarrow\quad \frac{a^2-\sigma^2}{2(\sigma^2)^2}=0.
\]
Thus,
\[
a^2-\sigma^2=0\quad\Longrightarrow\quad \sigma^2=a^2.
\]
This shows that the likelihood of generating $a\in\mathbb{R}$ is maximized when $\sigma^2=a^2$.

\subsection*{2.}

Let $x_1, x_2, \dots, x_m \sim N(0,I)$ be independent random vectors in $\mathbb{R}^n$. In this part, we analyze the distribution of their (unweighted and weighted) sums and determine the rank of the matrix
\[
C = \sum_{i=1}^m x_i x_i^T.
\]

\subsection*{(a) Distribution of $z = \sum_{i=1}^m x_i$}
Since the sum of independent Gaussian random vectors is Gaussian, we have
\[
z \sim N\Biggl(\sum_{i=1}^m \mathbb{E}[x_i],\, \sum_{i=1}^m \operatorname{Cov}(x_i)\Biggr)
= N\Bigl(0,\, mI\Bigr).
\]
Thus, 
\[
\mathbb{E}[z] = 0 \quad \text{and} \quad \operatorname{Cov}(z) = mI.
\]

\subsection*{(b) Distribution of the Weighted Sum $z_w = \sum_{i=1}^m w_i x_i$}
Let $w_1, w_2, \dots, w_m \in \mathbb{R}_+$ be positive weights. Note that each scaled vector $w_i x_i$ is distributed as
\[
w_i x_i \sim N\Bigl(0,\, w_i^2 I\Bigr).
\]
Since the $x_i$ are independent, the weighted sum $z_w$ is Gaussian with mean
\[
\mathbb{E}[z_w] = \sum_{i=1}^m w_i \mathbb{E}[x_i] = 0,
\]
and covariance
\[
\operatorname{Cov}(z_w) = \sum_{i=1}^m w_i^2\, \operatorname{Cov}(x_i)
= \Bigl(\sum_{i=1}^m w_i^2\Bigr) I.
\]
Thus, we obtain
\[
z_w \sim N\!\Bigl(0, \Bigl(\sum_{i=1}^m w_i^2\Bigr) I\Bigr).
\]

\subsection*{(c) Rank of $C = \sum_{i=1}^m x_i x_i^T$}
For each $i$, the outer product $x_i x_i^T$ is an $n\times n$ matrix of rank 1 (as shown in part (1a)). Hence, $C$ is the sum of $m$ rank-1 matrices. Since the $x_i$ are sampled from the continuous distribution $N(0,I)$, they are almost surely in \emph{general position} (i.e., any set of up to $n$ such vectors is linearly independent). Therefore:
\begin{itemize}
    \item If $m < n$, then almost surely the $m$ vectors $\{x_1, \dots, x_m\}$ are linearly independent, so
    \[
    \operatorname{rank}(C)=m.
    \]
    \item If $m \ge n$, then the $x_i$ will almost surely span $\mathbb{R}^n$, and hence
    \[
    \operatorname{rank}(C)=n.
    \]
\end{itemize}

\subsection{Neuroevolution}

In this exercise we consider solving the pole-balancing task using a direct policy search method with the CMA-ES. Our policy is encoded by a feed-forward neural network. In the notebook, two versions of the network were implemented: one that includes trainable bias parameters in the hidden and output layers, and one without bias. The following sections describe the network architecture (part 1) and summarize the experimental performance (part 2).

\subsection*{(a) Neural Network Architecture}
We use a network with a single hidden layer consisting of five neurons and a \texttt{tanh} activation. The output layer is a single neuron with a linear activation. The constructor of the network allows the user to select whether or not to include bias parameters. A code snippet implementing this in PyTorch is shown below.

\begin{lstlisting}[language=Python, caption={Definition of the policy network.}, basicstyle=\ttfamily\small]
import torch.nn as nn

class PolicyNetwork(nn.Module):
    def __init__(self, input_dim, hidden_dim=5, use_bias=True):
        super().__init__()

        # Hidden layer: a linear layer followed by tanh activation
        self.hidden = nn.Linear(input_dim, hidden_dim, bias=use_bias)

        # Output layer: a single neuron with linear activation
        self.output = nn.Linear(hidden_dim, 1, bias=use_bias)
        
    def forward(self, x):
        x = torch.tanh(self.hidden(x))
        x = self.output(x)  # Linear output
        return x

# Instantiate the policy network
# Set use_bias to True for an architecture with trainable biases,
# or False to have no bias parameters.
policy_net = PolicyNetwork(state_space_dimension, hidden_dim=5, use_bias=True)
\end{lstlisting}

In the code above, \texttt{hidden\_dim} can be changed, but is kept to 5 as a default value. The boolean parameter \texttt{use\_bias} allows for switching between the two architectures.

\subsection*{(b) Performance Comparison}
I compared the performance of the two architectures by running the learning procedure 10 times for each variant (with bias and without bias). Two metrics were recorded:
\begin{itemize}
    \item \textbf{Evaluations:} The number of evaluations (i.e., CMA-ES iterations) required to find a policy that balances the pole for 500 time steps.
    \item \textbf{Balancing Steps:} When testing the learned policies from a random starting position, the number of steps the pole remained balanced.
\end{itemize}

The summary of the experimental results is given in Table~\ref{tab:results}.

\begin{table}[ht]
\centering
\begin{tabular}{lcc}
\toprule
Architecture & Average Evaluations & Average Balancing Steps\\
\midrule
With bias    & 1422.0              & 330.9 \\
Without bias & 15.8                & 428.7 \\
\bottomrule
\end{tabular}
\caption{Performance comparison of policy networks with and without bias parameters.}
\label{tab:results}
\end{table}

\medskip

The results clearly indicate that the network without bias parameters converges much faster (only about 16 evaluations on average,
compared to over 1400 when using bias) and yields policies that keep the pole balanced for a longer duration (average of approximately
429 steps versus 331 steps).

A possible explanation is that adding bias parameters increases the number of free parameters in the model,
enlarging the search space. This makes the optimization using CMA-ES more challenging and slows down convergence.
Additionally, the simpler architecture without bias not only accelerates the search but also generalizes better to unseen starting conditions. This suggests that the increased complexity of the model is unnecessary and even counterproductive.