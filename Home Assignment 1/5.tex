\section*{Formulation of the Robber-Police Game as an MDP}

\begin{enumerate}

  \item[\textbf{(i)}]
    \textbf{State and Action Spaces.} \\
    We define each state \(s\) as a 4-tuple:
    \[
      s \;=\; \bigl(r_{\text{agent}},\,c_{\text{agent}},\,r_{\text{police}},\,c_{\text{police}}\bigr),
    \]
    where
    \[
      r_{\text{agent}},\,r_{\text{police}} \;\in\;\{0,1,2,3,4,5\},
      \quad
      c_{\text{agent}},\,c_{\text{police}} \;\in\;\{0,1,2\}.
    \]
    Therefore, the total number of states is
    \[
      |S| \;=\; 6 \times 3 \,\times\, 6 \times 3 \;=\; 324.
    \]
    We define the initial state as
    \[
      s_{\text{init}} \;=\; (0,\,0,\,1,\,2).
    \]

    The agent has five possible actions at each step:
    \[
      A \;=\; \{\uparrow,\;\downarrow,\;\leftarrow,\;\rightarrow,\;\text{stay}\}.
    \]
    Hence, \(\lvert A \rvert = 5\).

  \item[\textbf{(ii)}]
    \textbf{Reward Function.} \\
    We define the per-step reward function \(R(s,a)\) as follows:
    \[
      R(s, a) \;=\;
      \begin{cases}
        100000, & \text{if the agent is on a bank and the police is not there,} \\
        -10000, & \text{if the agent and the police share the same coordinates,} \\
        0, & \text{otherwise.}
      \end{cases}
    \]
    We then discount the reward by multiplying it by \(\gamma^{t-1}\), to encourage the agents to chose the best actions from the very beginning.

  \item[\textbf{(iii)}]
    \textbf{Transition Probabilities (with reflecting walls).} \\
    We now specify the transition probabilities
    \[
      P\bigl(s' \mid s, a\bigr),
    \]
    focusing on the example where the agent is at \(\text{Bank 1}\) and the police is at \(\text{Bank 4}\). 
    In coordinates, let
    \[
      s \;=\; (\,0,\,0,\,0,\,5).
    \]
    (Here \((0,0)\) denotes Bank~1 in row~0, column~0, and \((0,5)\) denotes Bank~4 in row~0, column~5.)

    \paragraph{Wall dynamics.}
    If either the agent or the police attempts to move outside the grid, 
    they \emph{remain in their current cell} (i.e.\ the move has no effect).
    For instance:
    \begin{itemize}
      \item If the agent (or police) is at row~0 and an \(\uparrow\) action is chosen,
            they remain in row~0.
      \item If at column~0 and a \(\leftarrow\) action is chosen,
            they remain in column~0.
      \item All other moves within the grid follow the usual row or column increment/decrement,
            bounded between row~\(0\) and row~\(2\), and column~\(0\) and column~\(5\).
    \end{itemize}
    
    \paragraph{Agent's move.}
    From \((r_{\text{agent}},\,c_{\text{agent}}) = (0,\,0)\), 
    and given the predefined action-space, the next agent position 
    \(\bigl(r_{\text{agent}}',\,c_{\text{agent}}'\bigr)\) is determined by the followings:
    \begin{itemize}
      \item With probability \(\pi(\uparrow\lvert\,s)\): agent tries \(\uparrow\); 
            but at row~0, it stays in \((0,0)\).
      \item With probability \(\pi(\leftarrow\lvert\,s)\): agent tries \(\leftarrow\); 
            but at column~0, it stays in \((0,0)\).
      \item With probability \(\pi(\rightarrow\lvert\,s)\): agent tries \(\rightarrow\); 
            this is valid, leading to \((0,1)\).
      \item With probability \(\pi(\downarrow\lvert\,s)\): agent tries \(\downarrow\); 
            this is valid, leading to \((1,0)\).
      \item With probability \(\pi(\text{stay}\lvert\,s)\): agent tries \text{stay}; 
            this is valid, leading to \((0,0)\).
      
    \end{itemize}

    \paragraph{Police's move.}
    Meanwhile, since the police is in the same row as the agent but to the right 
    \(\bigl((0,5)\,\text{vs.}\,(0,0)\bigr)\), 
    the problem statement tells us it moves 
    \(\uparrow\), \(\downarrow\), or \(\leftarrow\) with probability \(\tfrac{1}{3}\) each. 
    Specifically:
    \begin{itemize}
      \item With probability \(\tfrac{1}{3}\): police tries \texttt{Up}; 
            but at row~0, it stays in \((0,5)\).
      \item With probability \(\tfrac{1}{3}\): police tries \texttt{Down}; 
            this is valid, leading to \((1,5)\).
      \item With probability \(\tfrac{1}{3}\): police tries \texttt{Left}; 
            this is valid, leading to \((0,4)\).
    \end{itemize}

    \paragraph{Combining to get next‐state probabilities.}
    Let \(\bigl(r_{\text{agent}}',c_{\text{agent}}'\bigr)\) be the agent’s new position 
    after action~\(a\), 
    and \(\bigl(r_{\text{police}}',c_{\text{police}}'\bigr)\) be the result of the police’s stochastic move.  
    In general, the full next state is 
    \[
      s' \;=\; \bigl(r_{\text{agent}}',\,c_{\text{agent}}',\,r_{\text{police}}',\,c_{\text{police}}'\bigr).
    \]
    Because the agent’s sequence of actions depends on a policy \(\pi\) (which we do not yet know), 
    we keep \(\pi(a\,\lvert\,s)\) for the probability that action~\(a\) is chosen in state~\(s\). 
    
    Now, using ? as a placeholder to reflect every possible value assumable by a certain variable.
    What we end up with is:

    \begin{align*}
      P(0, 0, ?, ?) &= \pi(\uparrow \mid s) + \pi(\leftarrow \mid s) + \pi(\text{stay} \mid s) \\
      P(0, 1, ?, ?) &= \pi(\rightarrow \mid s) \\
      P(1, 0, ?, ?) &= \pi(\downarrow \mid s) \\
      P(?, ?, 0, 5) &= \tfrac{1}{3} \\
      P(?, ?, 1, 5) &= \tfrac{1}{3} \\
      P(?, ?, 0, 4) &= \tfrac{1}{3}
    \end{align*}

    We can then summarize the transition probabilities in of the 9 possible states \(s'\) in the following table:

    \begin{table}[h]
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{c|ccc}
    \textbf{Agent $\backslash$ Police} & $(?, ?, 0,5)$ & $(?, ?, 1,5)$ & $(?, ?, 0,4)$ \\ \hline
    $(0,0,?,?)$ & $\tfrac{1}{3}\Bigl(\pi(\uparrow\mid s)+\pi(\leftarrow\mid s)+\pi(\text{stay}\mid s)\Bigr)$ & $\tfrac{1}{3}\Bigl(\pi(\uparrow\mid s)+\pi(\leftarrow\mid s)+\pi(\text{stay}\mid s)\Bigr)$ & $\tfrac{1}{3}\Bigl(\pi(\uparrow\mid s)+\pi(\leftarrow\mid s)+\pi(\text{stay}\mid s)\Bigr)$ \\
    $(0,1,?,?)$ & $\tfrac{1}{3}\pi(\rightarrow\mid s)$ & $\tfrac{1}{3}\pi(\rightarrow\mid s)$ & $\tfrac{1}{3}\pi(\rightarrow\mid s)$ \\
    $(1,0,?,?)$ & $\tfrac{1}{3}\pi(\downarrow\mid s)$ & $\tfrac{1}{3}\pi(\downarrow\mid s)$ & $\tfrac{1}{3}\pi(\downarrow\mid s)$ \\
    \end{tabular}%
    }
    \caption{Transition probabilities for combined agent and police moves.}
    \label{tab:transition-probs}
    \end{table}

\end{enumerate}

